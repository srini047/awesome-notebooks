{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "latin-packing",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-23T14:22:16.610471Z",
     "iopub.status.busy": "2021-02-23T14:22:16.610129Z",
     "iopub.status.idle": "2021-02-23T14:22:16.627784Z",
     "shell.execute_reply": "2021-02-23T14:22:16.626866Z",
     "shell.execute_reply.started": "2021-02-23T14:22:16.610384Z"
    },
    "papermill": {},
    "tags": []
   },
   "source": [
    "<img width=\"10%\" alt=\"Naas\" src=\"https://landen.imgix.net/jtci2pxwjczr/assets/5ice39g4.png?w=160\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "compressed-wilson",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "# GitHub - Create newsletter based on repository activity\n",
    "<a href=\"https://app.naas.ai/user-redirect/naas/downloader?url=https://raw.githubusercontent.com/jupyter-naas/awesome-notebooks/master/GitHub/GitHub_Create_newsletter_based_on_repository_activity.ipynb\" target=\"_parent\"><img src=\"https://naasai-public.s3.eu-west-3.amazonaws.com/Open_in_Naas_Lab.svg\"/></a><br><br><a href=\"https://github.com/jupyter-naas/awesome-notebooks/issues/new?assignees=&labels=&template=template-request.md&title=Tool+-+Action+of+the+notebook+\">Template request</a> | <a href=\"https://github.com/jupyter-naas/awesome-notebooks/issues/new?assignees=&labels=bug&template=bug_report.md&title=GitHub+-+Create+newsletter+based+on+repository+activity:+Error+short+description\">Bug report</a> | <a href=\"https://app.naas.ai/user-redirect/naas/downloader?url=https://raw.githubusercontent.com/jupyter-naas/awesome-notebooks/master/Naas/Naas_Start_data_product.ipynb\" target=\"_parent\">Generate Data Product</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "religious-programmer",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "**Tags:** #tool #naas_drivers #naas #scheduler #asset #snippet #automation #ai #newsletter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fe9f56e-561c-4f52-aef8-b861c9462107",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "**Author:** [Suhas B](https://www.linkedin.com/in/suhasbrao/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "naas-description",
   "metadata": {
    "papermill": {},
    "tags": [
     "description"
    ]
   },
   "source": [
    "**Description:** This notebook allows users to create newsletters based on their repository activity on GitHub."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "distinguished-truth",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "## Input"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "numeric-mediterranean",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "potential-surfing",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "outputs": [],
   "source": [
    "from naas_drivers import github\n",
    "import naas\n",
    "import markdown2\n",
    "from IPython.core.display import display, HTML\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import requests\n",
    "from urllib.parse import urlencode"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aggressive-trustee",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "### Setup GitHub"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "705cb016-0aa8-4dde-b063-d2ea2b3d3c96",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "Before running the below cell ensure you have added a GitHub access token for repository using naas \n",
    "by running **naas.secret.add(name=\"API_NAME\", secret=\"API_KEY\")** and delete that cell.\n",
    "\n",
    "You can find more info [here](https://docs.naas.ai/features/secret#add-or-edit-secret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "018c579b-7ec6-444b-b4ff-518f759b2af3",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "outputs": [],
   "source": [
    "# GitHub credentials\n",
    "GITHUB_TOKEN = naas.secret.get(name=\"GITHUB_TOKEN\")\n",
    "\n",
    "# Repository\n",
    "repo_url = \"https://github.com/jupyter-naas/awesome-notebooks\"\n",
    "\n",
    "# Number of past days to follow activity\n",
    "no_past_days = 15"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5967641d-68a0-41b6-90f1-4b11a5260c53",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-14T14:03:21.396218Z",
     "iopub.status.busy": "2022-10-14T14:03:21.395984Z",
     "iopub.status.idle": "2022-10-14T14:03:21.400797Z",
     "shell.execute_reply": "2022-10-14T14:03:21.400222Z",
     "shell.execute_reply.started": "2022-10-14T14:03:21.396194Z"
    },
    "papermill": {},
    "tags": []
   },
   "source": [
    "### Setup Naas notifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40e86056-7788-4650-9ec5-1bff32558b65",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "outputs": [],
   "source": [
    "# List of email_receivers\n",
    "email_receivers = [\"hello@naas.ai\"]\n",
    "\n",
    "# EMAIL_FROM = None\n",
    "EMAIL_SUBJECT = \"✉️ Weekly Repository activity\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a92be08-6fc6-4112-a53b-03f06a653b87",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "### Schedule your notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2035d36-7471-4cf2-8783-254177d85c2b",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "Scheduling notebook to run At 12:00 on Sunday. You can modify it if you want "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1383d1a5-9741-4376-abe9-ae608709b7da",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Schedule your notebook\n",
    "naas.scheduler.add(cron=\"0 12 * * 0\")\n",
    "\n",
    "# -> Uncomment the line below to remove your scheduler\n",
    "# naas.scheduler.delete()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "registered-showcase",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tested-astrology",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "### Get Open issues from GitHub repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9a1c9fe-d178-42b2-b7c4-38497cd694d5",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get the issues from github naas_drivers\n",
    "# the retrived issues also contains PRs as\n",
    "# github creates a issue for every PR.\n",
    "df_issues_with_prs = github.connect(GITHUB_TOKEN).repos.get_issues(repo_url)\n",
    "print(\"Total Issues fetched:\", len(df_issues_with_prs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c7df1f4-2734-4540-b665-7948c42f6451",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "### Get Open issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dde5bad-cf01-4c20-ac6e-a66cf641b8bb",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_open_issues(repo_url):\n",
    "    \"\"\"\n",
    "    This function retrives open issues of a repository and returns a\n",
    "    dataframe with the following columns:\n",
    "\n",
    "    link_to_the_issue\n",
    "    issue_number\n",
    "    issue_title\n",
    "    issue_state\n",
    "    issue_assignees\n",
    "    last_created_date\n",
    "    last_created_time\n",
    "    last_updated_date\n",
    "    last_updated_time\n",
    "    link_to_the_pr\n",
    "    linked_pr_state\n",
    "    PR_activity\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    repository: str:\n",
    "        Repository url from Github.\n",
    "        Example : \"https://github.com/jupyter-naas/awesome-notebooks\"\n",
    "    \"\"\"\n",
    "\n",
    "    git_obj = github.connect(GITHUB_TOKEN)\n",
    "    repository = git_obj.get_repository_url(repo_url)\n",
    "    df = pd.DataFrame()\n",
    "    page, idx = 1, 0\n",
    "    while True:\n",
    "        params = {\n",
    "            \"per_page\": \"100\",\n",
    "            \"page\": page,\n",
    "        }\n",
    "\n",
    "        # Api to get open issues from github\n",
    "        url = f\"https://api.github.com/repos/{repository}/issues?state=open&{urlencode(params, safe='(),')}\"\n",
    "        res = requests.get(url, headers=git_obj.headers)\n",
    "        try:\n",
    "            res.raise_for_status()\n",
    "        except requests.HTTPError as e:\n",
    "            raise (e)\n",
    "\n",
    "        res_json = res.json()\n",
    "        if len(res_json) == 0:\n",
    "            break\n",
    "        for issue in res_json:\n",
    "            # Fetch the open issues, check node_id to see if it is an issue or PR\n",
    "\n",
    "            if issue[\"node_id\"].startswith(\"I_\"):\n",
    "\n",
    "                df.loc[idx, \"link_to_the_issue\"], df.loc[idx, \"issue_number\"] = (\n",
    "                    issue[\"html_url\"],\n",
    "                    issue[\"number\"],\n",
    "                )\n",
    "                df.loc[idx, \"issue_title\"], df.loc[idx, \"issue_state\"] = (\n",
    "                    issue[\"title\"],\n",
    "                    issue[\"state\"],\n",
    "                )\n",
    "\n",
    "                assigned = []\n",
    "                for assignee in issue[\"assignees\"]:\n",
    "                    assigned.append(assignee.get(\"login\"))\n",
    "                if assigned == []:\n",
    "                    df.loc[idx, \"issue_assignees\"] = \"None\"\n",
    "                else:\n",
    "                    df.loc[idx, \"issue_assignees\"] = \", \".join(assigned)\n",
    "\n",
    "                df.loc[idx, \"last_created_date\"] = (\n",
    "                    issue.get(\"created_at\").strip(\"Z\").split(\"T\")[0]\n",
    "                )\n",
    "                df.loc[idx, \"last_created_time\"] = (\n",
    "                    issue.get(\"created_at\").strip(\"Z\").split(\"T\")[-1]\n",
    "                )\n",
    "                df.loc[idx, \"last_updated_date\"] = (\n",
    "                    issue.get(\"updated_at\").strip(\"Z\").split(\"T\")[0]\n",
    "                )\n",
    "                df.loc[idx, \"last_updated_time\"] = (\n",
    "                    issue.get(\"updated_at\").strip(\"Z\").split(\"T\")[-1]\n",
    "                )\n",
    "                try:\n",
    "                    df.loc[idx, \"link_to_the_pr\"] = issue.get(\"pull_request\")[\n",
    "                        \"html_url\"\n",
    "                    ]\n",
    "                    pr = requests.get(\n",
    "                        issue.get(\"pull_request\")[\"url\"], headers=git_obj.headers\n",
    "                    ).json()\n",
    "\n",
    "                    df.loc[idx, \"linked_pr_state\"] = pr.get(\"state\")\n",
    "\n",
    "                    date_format = \"%Y-%m-%d\"\n",
    "                    delta = datetime.datetime.now() - datetime.datetime.strptime(\n",
    "                        df.loc[idx, \"last_updated_date\"], date_format\n",
    "                    )\n",
    "                    df.loc[idx, \"PR_activity\"] = f\"No activity since {delta.days} days\"\n",
    "\n",
    "                except Exception as e:\n",
    "                    # print(e)\n",
    "                    df.loc[idx, \"linked_pr_state\"] = \"None\"\n",
    "                    df.loc[idx, \"PR_activity\"] = \"None\"\n",
    "                idx += 1\n",
    "        page += 1\n",
    "    return df\n",
    "\n",
    "\n",
    "df_open_issues = get_open_issues(repo_url)\n",
    "print(\"Total open Issues fetched:\", len(df_open_issues))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f11c767a-911a-4b23-911b-668ddf2eaad0",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "outputs": [],
   "source": [
    "# let us see few open issues fetched from github\n",
    "df_open_issues.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60eeb271-f4e6-42c5-9687-095ac18903e6",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "### Get closed issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f710ba9-dd97-46a7-a9c0-4b3299146617",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_closed_issues(repo_url):\n",
    "    \"\"\"\n",
    "    This function retrives the closed issues of a repository and returns a\n",
    "    dataframe with the following columns:\n",
    "\n",
    "    link_to_the_issue\n",
    "    issue_number\n",
    "    issue_title\n",
    "    issue_state\n",
    "    issue_assignees\n",
    "    last_created_date\n",
    "    last_created_time\n",
    "    last_updated_date\n",
    "    last_updated_time\n",
    "    link_to_the_pr\n",
    "    linked_pr_state\n",
    "    PR_activity\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    repository: str:\n",
    "        Repository url from Github.\n",
    "        Example : \"https://github.com/jupyter-naas/awesome-notebooks\"\n",
    "    \"\"\"\n",
    "\n",
    "    git_obj = github.connect(GITHUB_TOKEN)\n",
    "    repository = git_obj.get_repository_url(repo_url)\n",
    "    df = pd.DataFrame()\n",
    "    page, idx = 1, 0\n",
    "    while True:\n",
    "        params = {\n",
    "            \"per_page\": \"100\",\n",
    "            \"page\": page,\n",
    "        }\n",
    "\n",
    "        url = f\"https://api.github.com/repos/{repository}/issues?state=closed&{urlencode(params, safe='(),')}\"\n",
    "        res = requests.get(url, headers=git_obj.headers)\n",
    "        try:\n",
    "            res.raise_for_status()\n",
    "        except requests.HTTPError as e:\n",
    "            raise (e)\n",
    "\n",
    "        res_json = res.json()\n",
    "        if len(res_json) == 0:\n",
    "            break\n",
    "        for issue in res_json:\n",
    "\n",
    "            if issue[\"node_id\"].startswith(\"I_\"):\n",
    "\n",
    "                df.loc[idx, \"link_to_the_issue\"], df.loc[idx, \"issue_number\"] = (\n",
    "                    issue[\"html_url\"],\n",
    "                    issue[\"number\"],\n",
    "                )\n",
    "                df.loc[idx, \"issue_title\"], df.loc[idx, \"issue_state\"] = (\n",
    "                    issue[\"title\"],\n",
    "                    issue[\"state\"],\n",
    "                )\n",
    "\n",
    "                assigned = []\n",
    "                for assignee in issue[\"assignees\"]:\n",
    "                    assigned.append(assignee.get(\"login\"))\n",
    "                if assigned == []:\n",
    "                    df.loc[idx, \"issue_assignees\"] = \"None\"\n",
    "                else:\n",
    "                    df.loc[idx, \"issue_assignees\"] = \", \".join(assigned)\n",
    "\n",
    "                df.loc[idx, \"last_created_date\"] = (\n",
    "                    issue.get(\"created_at\").strip(\"Z\").split(\"T\")[0]\n",
    "                )\n",
    "                df.loc[idx, \"last_created_time\"] = (\n",
    "                    issue.get(\"created_at\").strip(\"Z\").split(\"T\")[-1]\n",
    "                )\n",
    "                df.loc[idx, \"last_updated_date\"] = (\n",
    "                    issue.get(\"updated_at\").strip(\"Z\").split(\"T\")[0]\n",
    "                )\n",
    "                df.loc[idx, \"last_updated_time\"] = (\n",
    "                    issue.get(\"updated_at\").strip(\"Z\").split(\"T\")[-1]\n",
    "                )\n",
    "                try:\n",
    "\n",
    "                    df.loc[idx, \"link_to_the_pr\"] = issue.get(\"pull_request\")[\n",
    "                        \"html_url\"\n",
    "                    ]\n",
    "                    pr = requests.get(\n",
    "                        issue.get(\"pull_request\")[\"url\"], headers=git_obj.headers\n",
    "                    ).json()\n",
    "\n",
    "                    df.loc[idx, \"linked_pr_state\"] = pr.get(\"state\")\n",
    "\n",
    "                    date_format = \"%Y-%m-%d\"\n",
    "                    delta = datetime.datetime.now() - datetime.datetime.strptime(\n",
    "                        df.loc[idx, \"last_updated_date\"], date_format\n",
    "                    )\n",
    "                    df.loc[idx, \"PR_activity\"] = f\"No activity since {delta.days} days\"\n",
    "\n",
    "                except Exception as e:\n",
    "                    # print(e)\n",
    "                    df.loc[idx, \"linked_pr_state\"] = \"None\"\n",
    "                    df.loc[idx, \"PR_activity\"] = \"None\"\n",
    "                idx += 1\n",
    "        page += 1\n",
    "    return df\n",
    "\n",
    "\n",
    "df_closed_issues = get_closed_issues(repo_url)\n",
    "print(\"Total closed Issues fetched:\", len(df_closed_issues))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15088c35-9147-4aa7-9108-ffc0e1f4de11",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_closed_issues.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33645684-7027-497c-a7ee-a2f0337360be",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "### Get open PRs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae8a1ff2-d0e2-4a5d-a33e-66ee74b45413",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_open_PRs(repo_url):\n",
    "    \"\"\"\n",
    "    This function retrives open PRs of a repository and returns a\n",
    "    dataframe with the following columns:\n",
    "\n",
    "    - ID                      int64\n",
    "    - ISSUE_URL               object\n",
    "    - PR_NUMBER               int64\n",
    "    - PR_STATE                object\n",
    "    - TITLE                   object\n",
    "    - ISSUE_REF_TITILE        object\n",
    "    - ASSIGNEES_PROFILE       object\n",
    "    - FIRST_CREATED_DATE      object\n",
    "    - FIRST_CREATED_TIME      object\n",
    "    - LAST_UPDATED_DATE       object\n",
    "    - LAST_UPDATED_TIME       object\n",
    "    - COMMITS_URL             object\n",
    "    - REVIEW_COMMENTS_URL     object\n",
    "    - ISSUE_COMMENTS_URL      object\n",
    "    - ASSIGNEES               object\n",
    "    - REQUESTED_REVIEWERS     object\n",
    "    - PR_ACTIVITY             object\n",
    "    Parameters\n",
    "    ----------\n",
    "    repository: str:\n",
    "        Repository url from Github.\n",
    "        Example : \"https://github.com/jupyter-naas/awesome-notebooks\"\n",
    "    \"\"\"\n",
    "    # Get organisation and repository from url\n",
    "    git_obj = github.connect(GITHUB_TOKEN)\n",
    "    repository = git_obj.get_repository_url(repo_url)\n",
    "\n",
    "    df = pd.DataFrame()\n",
    "    page = 1\n",
    "    while True:\n",
    "        params = {\n",
    "            \"per_page\": \"100\",\n",
    "            \"page\": page,\n",
    "        }\n",
    "        # below is api to get open PRs from github\n",
    "        url = f\"https://api.github.com/repos/{repository}/pulls?&{urlencode(params, safe='(),')}\"\n",
    "        res = requests.get(url, headers=git_obj.headers)\n",
    "        try:\n",
    "            res.raise_for_status()\n",
    "        except requests.HTTPError as e:\n",
    "            raise (e)\n",
    "        res_json = res.json()\n",
    "        if len(res_json) == 0:\n",
    "            break\n",
    "\n",
    "        for idx, r in enumerate(res_json):\n",
    "\n",
    "            df.loc[idx, \"id\"] = r.get(\"id\")\n",
    "            df.loc[idx, \"issue_url\"] = r.get(\"html_url\")\n",
    "            df.loc[idx, \"PR_number\"] = r.get(\"number\")\n",
    "            df.loc[idx, \"PR_state\"] = \"open\"\n",
    "            df.loc[idx, \"Title\"] = r.get(\"title\")\n",
    "\n",
    "            df.loc[idx, \"issue_ref_title\"] = r.get(\"head\").get(\"ref\")\n",
    "\n",
    "            df.loc[idx, \"first_created_date\"] = (\n",
    "                r.get(\"created_at\").strip(\"Z\").split(\"T\")[0]\n",
    "            )\n",
    "            df.loc[idx, \"first_created_time\"] = (\n",
    "                r.get(\"created_at\").strip(\"Z\").split(\"T\")[-1]\n",
    "            )\n",
    "            df.loc[idx, \"last_updated_date\"] = (\n",
    "                r.get(\"updated_at\").strip(\"Z\").split(\"T\")[0]\n",
    "            )\n",
    "            df.loc[idx, \"last_updated_time\"] = (\n",
    "                r.get(\"updated_at\").strip(\"Z\").split(\"T\")[-1]\n",
    "            )\n",
    "\n",
    "            df.loc[idx, \"commits_url\"] = r.get(\"commits_url\")\n",
    "            df.loc[idx, \"review_comments_url\"] = r.get(\"review_comments_url\")\n",
    "            df.loc[idx, \"issue_comments_url\"] = r.get(\"comments_url\")\n",
    "\n",
    "            assignees_lst, reviewers_lst = [], []\n",
    "            assignees_profile = []\n",
    "            for assignee in r.get(\"assignees\"):\n",
    "                assignees_lst.append(assignee.get(\"login\"))\n",
    "                assignees_profile.append(assignee.get(\"html_url\"))\n",
    "            for reviewer in r.get(\"requested_reviewers\"):\n",
    "                reviewers_lst.append(reviewer.get(\"login\"))\n",
    "\n",
    "            if assignees_lst == []:\n",
    "                df.loc[idx, \"assignees\"] = \"None\"\n",
    "                df.loc[idx, \"assignees_profile\"] = \"None\"\n",
    "            elif assignees_lst:\n",
    "                df.loc[idx, \"assignees\"] = \", \".join(assignees_lst)\n",
    "                df.loc[idx, \"assignees_profile\"] = \", \".join(assignees_profile)\n",
    "\n",
    "            if reviewers_lst == []:\n",
    "                df.loc[idx, \"requested_reviewers\"] = \"None\"\n",
    "            elif reviewers_lst:\n",
    "                df.loc[idx, \"requested_reviewers\"] = \", \".join(reviewers_lst)\n",
    "\n",
    "            date_format = \"%Y-%m-%d\"\n",
    "            delta = datetime.datetime.now() - datetime.datetime.strptime(\n",
    "                df.loc[idx, \"last_updated_date\"], date_format\n",
    "            )\n",
    "            df.loc[idx, \"PR_activity\"] = f\"No activity since {delta.days} days\"\n",
    "\n",
    "            df[\"PR_number\"] = df.PR_number.astype(\"int\")\n",
    "            df.id = df.id.astype(\"int\")\n",
    "        page += 1\n",
    "    return df\n",
    "\n",
    "\n",
    "df_open_PRS = get_open_PRs(repo_url)\n",
    "print(\"Total open PRs:\", len(df_open_PRS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "054eb611-3b49-4a1f-986b-b911db5764d0",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_open_PRS.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c59b682d-80a8-44b6-8bcf-b5d8fd84dbca",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "### Get closed PRs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbe5f068-8c28-48d9-92b5-0364d5577d38",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_closed_PRs(repo_url):\n",
    "    \"\"\"\n",
    "    This function retrives the closed PRs of a repository and returns a\n",
    "    dataframe with the following columns:\n",
    "        - ID                      int64\n",
    "        - ISSUE_URL               object\n",
    "        - PR_NUMBER               int64\n",
    "        - PR_STATE                object\n",
    "        - TITLE                   object\n",
    "        - FIRST_CREATED_DATE      object\n",
    "        - FIRST_CREATED_TIME      object\n",
    "        - LAST_UPDATED_DATE       object\n",
    "        - LAST_UPDATED_TIME       object\n",
    "        - COMMITS_URL             object\n",
    "        - REVIEW_COMMENTS_URL     object\n",
    "        - ISSUE_COMMENTS_URL      object\n",
    "        - ASSIGNEES               object\n",
    "        - REQUESTED_REVIEWERS     object\n",
    "        - REVIEWERS_PROFILE       object\n",
    "        - PR_ACTIVITY             object\n",
    "        Parameters\n",
    "        ----------\n",
    "        repository: str:\n",
    "            Repository url from Github.\n",
    "            Example : \"https://github.com/jupyter-naas/awesome-notebooks\"\n",
    "    \"\"\"\n",
    "\n",
    "    git_obj = github.connect(GITHUB_TOKEN)\n",
    "    repository = git_obj.get_repository_url(repo_url)\n",
    "    df = pd.DataFrame()\n",
    "    page, idx = 1, 0\n",
    "\n",
    "    while True:\n",
    "        params = {\n",
    "            \"per_page\": \"200\",\n",
    "            \"page\": page,\n",
    "        }\n",
    "        url = f\"https://api.github.com/repos/{repository}/pulls?state=closed&{urlencode(params, safe='(),')}\"\n",
    "        res = requests.get(url, headers=git_obj.headers)\n",
    "        try:\n",
    "            res.raise_for_status()\n",
    "        except requests.HTTPError as e:\n",
    "            raise (e)\n",
    "        res_json = res.json()\n",
    "        if len(res_json) == 0:\n",
    "            break\n",
    "\n",
    "        for _, r in enumerate(res_json):\n",
    "\n",
    "            df.loc[idx, \"id\"] = r.get(\"id\")\n",
    "            df.loc[idx, \"issue_url\"] = r.get(\"html_url\")\n",
    "            df.loc[idx, \"PR_number\"] = r.get(\"number\")\n",
    "            df.loc[idx, \"PR_state\"] = \"open\"\n",
    "            df.loc[idx, \"Title\"] = r.get(\"title\")\n",
    "\n",
    "            df.loc[idx, \"first_created_date\"] = (\n",
    "                r.get(\"created_at\").strip(\"Z\").split(\"T\")[0]\n",
    "            )\n",
    "            df.loc[idx, \"first_created_time\"] = (\n",
    "                r.get(\"created_at\").strip(\"Z\").split(\"T\")[-1]\n",
    "            )\n",
    "            df.loc[idx, \"last_updated_date\"] = (\n",
    "                r.get(\"updated_at\").strip(\"Z\").split(\"T\")[0]\n",
    "            )\n",
    "            df.loc[idx, \"last_updated_time\"] = (\n",
    "                r.get(\"updated_at\").strip(\"Z\").split(\"T\")[-1]\n",
    "            )\n",
    "\n",
    "            df.loc[idx, \"commits_url\"] = r.get(\"commits_url\")\n",
    "            df.loc[idx, \"review_comments_url\"] = r.get(\"review_comments_url\")\n",
    "            df.loc[idx, \"issue_comments_url\"] = r.get(\"comments_url\")\n",
    "\n",
    "            assignees_lst, reviewers_lst = [], []\n",
    "            reviewers_profile = []\n",
    "            for assignee in r.get(\"assignees\"):\n",
    "                assignees_lst.append(assignee.get(\"login\"))\n",
    "            for reviewer in r.get(\"requested_reviewers\"):\n",
    "                reviewers_lst.append(reviewer.get(\"login\"))\n",
    "                reviewers_profile.append(reviewer.get(\"html_url\"))\n",
    "\n",
    "            if assignees_lst == []:\n",
    "                df.loc[idx, \"assignees\"] = \"None\"\n",
    "            elif assignees_lst:\n",
    "                df.loc[idx, \"assignees\"] = \", \".join(assignees_lst)\n",
    "\n",
    "            if reviewers_lst == []:\n",
    "                df.loc[idx, \"requested_reviewers\"] = \"None\"\n",
    "                df.loc[idx, \"reviewers_profile\"] = \"None\"\n",
    "            elif reviewers_lst:\n",
    "                df.loc[idx, \"requested_reviewers\"] = \", \".join(reviewers_lst)\n",
    "                df.loc[idx, \"reviewers_profile\"] = \", \".join(reviewers_profile)\n",
    "\n",
    "            date_format = \"%Y-%m-%d\"\n",
    "            delta = datetime.datetime.now() - datetime.datetime.strptime(\n",
    "                df.loc[idx, \"last_updated_date\"], date_format\n",
    "            )\n",
    "            df.loc[idx, \"PR_activity\"] = f\"No activity since {delta.days} days\"\n",
    "\n",
    "            df[\"PR_number\"] = df.PR_number.astype(\"int\")\n",
    "            df.id = df.id.astype(\"int\")\n",
    "            idx += 1\n",
    "        page += 1\n",
    "    return df\n",
    "\n",
    "\n",
    "df_closed_prs = get_closed_PRs(repo_url)\n",
    "print(\"Total closed PRs:\", len(df_closed_prs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13eeaad1-c21d-45a8-b3dc-31c55db73793",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "### Get KPIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adc0dcfb-8373-4e33-ae21-573c1e7eef5c",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get the latest issues between previous_date and current_date\n",
    "# This is acheived by using a mask as shown below\n",
    "current_date = datetime.date.today()\n",
    "previous_date = datetime.datetime.today() - datetime.timedelta(days=no_past_days)\n",
    "previous_date = previous_date.date()\n",
    "no_issues_created = 0\n",
    "no_issues_closed = 0\n",
    "\n",
    "mask_for_open_issues = (df_open_issues[\"last_created_date\"] >= str(previous_date)) & (\n",
    "    df_open_issues[\"last_created_date\"] <= str(current_date)\n",
    ")\n",
    "\n",
    "\n",
    "mask_for_closed_issues = (\n",
    "    df_closed_issues[\"last_created_date\"] >= str(previous_date)\n",
    ") & (df_closed_issues[\"last_created_date\"] <= str(current_date))\n",
    "\n",
    "\n",
    "mask_for_closed_PRs = (df_closed_prs[\"last_updated_date\"] >= str(previous_date)) & (\n",
    "    df_closed_prs[\"last_updated_date\"] <= str(current_date)\n",
    ")\n",
    "\n",
    "mask_for_open_PRs = (df_open_PRS[\"last_updated_date\"] >= str(previous_date)) & (\n",
    "    df_open_PRS[\"last_updated_date\"] <= str(current_date)\n",
    ")\n",
    "\n",
    "\n",
    "df_open_issues_needed = df_open_issues.loc[mask_for_open_issues]\n",
    "df_closed_issues_needed = df_closed_issues.loc[mask_for_closed_issues]\n",
    "df_closed_PRs_needed = df_closed_prs.loc[mask_for_closed_PRs]\n",
    "df_open_PRs_needed = df_open_PRS.loc[mask_for_open_PRs]\n",
    "\n",
    "no_issues_created = len(df_open_issues_needed)\n",
    "no_issues_closed = len(df_closed_issues_needed)\n",
    "no_PRs_closed = len(df_closed_PRs_needed)\n",
    "no_PRs_open = len(df_open_PRs_needed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03c306ee-d4e8-4a0d-8e7e-481b3001f570",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "### Get issues for open PRs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92da627c-c5da-40ea-897e-00ecf3fa10ca",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_issue_objs_from_prs(df_opens, df_open_PRs_needed):\n",
    "    # This function fetches issues that link to PRs\n",
    "    df = pd.DataFrame()\n",
    "    for values in df_open_PRs_needed[\"issue_url\"]:\n",
    "\n",
    "        df_new = df_opens[df_opens[\"link_to_the_issue\"] == values]\n",
    "        df = df.append(df_new, ignore_index=True)\n",
    "    return df\n",
    "\n",
    "\n",
    "df_issues_for_opens_prs = get_issue_objs_from_prs(\n",
    "    df_issues_with_prs, df_open_PRs_needed\n",
    ")\n",
    "# df_issues_for_opens_prs.head"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f537deab-f740-485c-baa2-d7dc1f70a837",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "### Create a content for mail\n",
    "This is later to converted to a HTML content for the mail. Modify these contents based on your needs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0bf7dc0-6256-4e51-8d39-2b5ab8646c77",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "outputs": [],
   "source": [
    "def show_open_issues(open_issues_required) -> str:\n",
    "    #     BigFunctions - Get sentiment score #1240\n",
    "    #     open_issues_required = open_issues_required.reset_index()\n",
    "    open_issues_required.head()\n",
    "    temp_str = \"\"\n",
    "    for row in range(len(open_issues_required)):\n",
    "\n",
    "        line = f\"\"\"- [{open_issues_required[\"issue_title\"][row]} #{int(open_issues_required[\"issue_number\"][row])}]({open_issues_required[\"link_to_the_issue\"][row]})\n",
    "        \"\"\"\n",
    "        temp_str += \"\\n\" + line\n",
    "\n",
    "    return temp_str\n",
    "\n",
    "\n",
    "def show_closed_issues(closed_issues_required, closed_prs_needed) -> str:\n",
    "    closed_issues_required = closed_issues_required.reset_index()\n",
    "    closed_prs_needed = closed_prs_needed.reset_index()\n",
    "    temp_str = \"\"\n",
    "    for row in range(len(closed_issues_required)):\n",
    "\n",
    "        line = f\"\"\"- [ {closed_issues_required[\"issue_title\"][row]} \\\n",
    "        {int(closed_issues_required[\"issue_number\"][row])}]({closed_issues_required[\"link_to_the_issue\"][row]}),\n",
    "    closed by #[{closed_prs_needed[\"PR_number\"][row]}]({closed_prs_needed[\"issue_url\"][row]}) \\\n",
    "    by [@{closed_prs_needed[\"requested_reviewers\"][row]}]({closed_prs_needed[\"reviewers_profile\"][row]})\n",
    "    \"\"\"\n",
    "\n",
    "        temp_str += \"\\n\" + line\n",
    "\n",
    "    return temp_str\n",
    "\n",
    "\n",
    "def show_open_PRs(open_prs_req, issues_for_open_prs) -> str:\n",
    "    open_prs_req = open_prs_req.reset_index()\n",
    "    temp_str = \"\"\n",
    "    df_1 = open_prs_req\n",
    "    df_2 = issues_for_open_prs\n",
    "\n",
    "    for row in range(len(open_prs_req)):\n",
    "\n",
    "        date_str = (\n",
    "            df_1[\"first_created_date\"][row] + \" \" + df_1[\"first_created_time\"][row]\n",
    "        )\n",
    "        date_created = datetime.datetime.strptime(date_str, \"%Y-%m-%d %H:%M:%S\")\n",
    "        no_days_ago = (datetime.date.today() - date_created.date()).days\n",
    "\n",
    "        line = f\"\"\"- [#{df_1[\"PR_number\"][row]}]({df_1[\"issue_url\"][row]}), solving Issue \\\n",
    "        [**{df_2[\"issue_title\"][row].capitalize()} #{df_2[\"issue_number\"][row]}**]({df_2[\"link_to_the_issue\"][row]}) from \\\n",
    "        @[{df_1[\"assignees\"][row]}]({df_1[\"assignees_profile\"][row]}) opened \\\n",
    "        {no_days_ago} days ago ({df_1[\"first_created_date\"][row]}) \n",
    "        \n",
    "        \"\"\"\n",
    "        temp_str += \"\\n\" + line\n",
    "\n",
    "    return temp_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2776af80-cba0-4d17-9f29-fb7733aee853",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "outputs": [],
   "source": [
    "# content = open(EMAIL_CONTENT_MD, \"r\").read()\n",
    "\n",
    "content = f\"\"\"\n",
    "Hello there 👋,\n",
    "\n",
    "Here is what happened over the past {no_past_days} days on **{repo_url.split(\"/\")[-1]}**.\n",
    "\n",
    "\n",
    "### Issues created = {no_issues_created}\n",
    "\n",
    "{show_open_issues(df_open_issues_needed)}\n",
    "\n",
    "### Issues closed = {no_issues_closed}\n",
    "\n",
    "{show_closed_issues(df_closed_issues_needed, df_closed_PRs_needed)}\n",
    "\n",
    "### PRs Open = {no_PRs_open}\n",
    "\n",
    "{show_open_PRs(df_open_PRs_needed, df_issues_for_opens_prs)}\n",
    "\n",
    "\n",
    "Check out the latest issues activity on [GitHub]({repo_url})⭐\n",
    "\n",
    "Cheers 😊\n",
    "\"\"\"\n",
    "\n",
    "# Create a markdown content based on the above content\n",
    "# this allows us to send email as markdown\n",
    "md = markdown2.markdown(content)\n",
    "display(HTML(md))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lonely-pacific",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-02T23:32:10.789097Z",
     "iopub.status.busy": "2021-07-02T23:32:10.788829Z",
     "iopub.status.idle": "2021-07-02T23:32:10.796900Z",
     "shell.execute_reply": "2021-07-02T23:32:10.796358Z",
     "shell.execute_reply.started": "2021-07-02T23:32:10.789033Z"
    },
    "papermill": {},
    "tags": []
   },
   "source": [
    "## Output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a28950bb-1d7d-4835-a83a-faac837ebc7c",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "### Send mail to receivers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db205965-a2dc-4541-ba8e-db3250d1cff0",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "outputs": [],
   "source": [
    "for receiver in email_receivers:\n",
    "    naas.notification.send(email_to=receiver, subject=EMAIL_SUBJECT, html=md)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0532ab5e-34fd-4976-aa59-b0d4a0d998f0",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "naas": {
   "notebook_id": "8ae2c7c1e9a984b87050a86432e0e8d09f71f62e51e2bb84533b97ad4494e04d",
   "notebook_path": "GitHub/GitHub_Create_newsletter_based_on_repository_activity.ipynb"
  },
  "papermill": {
   "default_parameters": {},
   "environment_variables": {},
   "parameters": {},
   "version": "2.3.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}